{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=color:blue>網頁資料擷取</span>\n",
    "\n",
    "<p style=color:red>擷取網頁資料的前題是不能觸犯著作權:</p>\n",
    "+ https://www.tipo.gov.tw/ct.asp?xItem=219598&ctNode=7561&mp=1\n",
    "+ https://udn.com/news/story/6871/3221682\n",
    "\n",
    "這個單元例子僅用來說明由網頁擷取資料的入門技巧。\n",
    "+ 使用re\n",
    "+ 使用BeautifulSoup\n",
    "+ 使用Selenium\n",
    "\n",
    "## <span style=color:blue>解析網址</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 單純網址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from urllib.parse import urlparse\n",
    "url = 'https://tw.stock.yahoo.com/news_list/url/d/e/'\n",
    "up  = urlparse(url)\n",
    "print(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from urllib.parse import urlparse\n",
    "url = 'https://www.cwb.gov.tw/V7/forecast/index.htm'\n",
    "up  = urlparse(url)\n",
    "print(up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 有get參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from urllib.parse import urlparse\n",
    "url = 'https://tw.stock.yahoo.com/q/q?s=2330'\n",
    "up  = urlparse(url)\n",
    "print(up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from urllib.parse import urlparse\n",
    "url = 'https://ecshweb.pchome.com.tw/search/v3.3/?q=pc&scope=all'\n",
    "up  = urlparse(url)\n",
    "print(up.query.split('&'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ scheme: 通訊協定\n",
    "+ netloc: 網域名稱\n",
    "+ path: 網頁所在路徑與檔名\n",
    "+ query；GET參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## <span style=color:blue>透過requests.get(url)擷取網頁的內容</span>\n",
    "\n",
    "    import requests\n",
    "    r = requests.get(url)\n",
    "    \n",
    "註: 萬一被阻擋，可以嘗試設定user agent\n",
    "\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Safari/537.36',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Connection' : 'Keep-Alive',\n",
    "        'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        'Accept-Encoding':'gzip, deflate, sdch',\n",
    "        'Accept-Languate': 'en-US,en;q=0.8'}\n",
    "    \n",
    "    r = requests.get(url,headers=headers)\n",
    "    \n",
    "你可以從chrome瀏覽器找到各式user agent字串：按Ctrl-Shift-I啟動開發者工具，在Network選單，按右上選項圖示後選More tools>Network conditions。\n",
    " <img src=\"attachment:user_agent.png\" width=\"450\">\n",
    " \n",
    "### 在URL裡傳遞參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "keys = {'search_query': 'python'}   \n",
    "r=requests.get('https://www.youtube.com/results',params=keys)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 擷取網頁的內容\n",
    "####  方式一: r.content (它是bytes型態) \n",
    "可透過下面方式將bytes轉str\n",
    "+ 轉換方法一: r.content.decode('utf-8')\n",
    "+ 轉換方法二: str(r.content,encoding='utf-8')\n",
    "\n",
    "str轉bytes\n",
    "+ 轉換方法一: s.encode('utf-8')\n",
    "+ 轉換方法二: bytes(s, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://www.cwb.gov.tw/V7/forecast/index.htm'\n",
    "r = requests.get(url)\n",
    "for i in r.content.decode('utf-8').splitlines()[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方式二: r.text (它是str型態)\n",
    "如下面所示，requests編碼方式為ISO-8859-1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://www.cwb.gov.tw/V7/forecast/index.htm'\n",
    "#html = requests.get(url).content.decode('utf-8','ignore').splitlines()\n",
    "r = requests.get(url)\n",
    "print(r.encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用r.encoding='utf-8'將編碼改為'utf-8'編碼後，處理網頁內容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://www.cwb.gov.tw/V7/forecast/index.htm'\n",
    "r = requests.get(url)\n",
    "r.encoding = 'utf-8'\n",
    "for i in r.text.splitlines()[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## <span style=color:blue>使用re模組擷取資訊</span>\n",
    "### HTML網頁格式\n",
    "HTML標記         | 用途說明  \n",
    "-----------------|----------\n",
    "$\\text{<html>...</html>}$   | <p align=\"left\">標記...為HTML文件</p>\n",
    "$\\text{<head>...</head>}$   | <p align=\"left\">標記...為HTML文件標頭</p>\n",
    "$\\text{<title>...</title>}$   | <p align=\"left\">標記...為HTML文件標題，通常會顯示在瀏覽器標題列</p>\n",
    "$\\text{<body>...</body>}$   | <p align=\"left\">標記...為HTML文件內容</p>\n",
    "$\\text{<script>...</script>}$   |  <p align=\"left\">標記...為描述語言</p>\n",
    "$\\text{<h1>...</h1>}$   | <p align=\"left\">標記...為標題(等級為h1,...,h6)</p>\n",
    "$\\text{<p>...</p>}$   | <p align=\"left\">標記...為文字段落</p>\n",
    "$\\text{<div>...</div>}$   |　 <p align=\"left\">排版用格式標記，...通常為內文大段落或顯示分塊</p>\n",
    "$\\text{<span>...</span>}$   | <p align=\"left\"> 類似$\\text{<div>}$，通常用在小段落</p>\n",
    "$\\text{<table>...</table>}$   |　<p align=\"left\">標記...為表格呈現內容</p>\n",
    "$\\text{<img src='...'>}$   |　<p align=\"left\">顯示圖形檔設定</p>\n",
    "$\\text{<a href='...'>}$   |　<p align=\"left\">外部連結設定</p>\n",
    "\n",
    "#### 例子:使用re擷取網頁裡的新聞標題\n",
    "https://udn.com/news/cate/2/7226 網頁裡新聞標題寫在$\\text{<h2> ... </h2>}$段落，如下範例\n",
    "\n",
    "     <h2 style=\"width:100%\">專利戰高通告贏蘋果 陸將禁售iPhone X以前機種 <time>22:29</time></h2>   \n",
    "     <h2>先從海外版施行 日本漫畫週刊少年Jump也走向數位訂閱制<span class=\"i-video1\"></span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "url = 'https://udn.com/news/cate/2/7226'\n",
    "html = requests.get(url).content.decode('utf-8')\n",
    "for idx,title in enumerate(re.finditer(r'<h2[^>]*?>([^<]*?)(<time.+?/time>)?(<span.+?/span>)?</h2>',html)):\n",
    "    print('{:4d}. {}'.format(idx+1,title.group(1)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## <span style=color:blue> 使用BeautifulSoup模組擷取資訊 </span>\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "\n",
    "安裝\n",
    "\n",
    "    conda install -c anaconda beautifulsoup4\n",
    "    \n",
    "找到所有$\\text{<h2> ... </h2>}$段落程式片段\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    url = 'https://udn.com/news/cate/2/7226'\n",
    "    html = requests.get(url).content.decode('utf-8')\n",
    "    sp = BeautifulSoup(html,'html.parser')\n",
    "    for link in sp.find_all('h2'):\n",
    "        print('{}'.format(link.text)) \n",
    "\n",
    "指令範例                | 說明\n",
    "-----------------------|----------\n",
    "sp.find('a'[,key])           | <p align='left'>傳回第一個符合的內容</p>\n",
    "sp.find_all('a'[,key])       | <p align='left'>傳回所有符合的內容</p>\n",
    "sp.title/sp.title.text | <p align='left'>傳回$\\text{<title>網頁標題</title>}$</p>\n",
    "sp.text                | <p align='left'>傳回去掉HTML標籤的內容</p>\n",
    "\n",
    "#### 例子:使用BeautifulSoup擷取網頁裡的新聞標題    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = 'https://udn.com/news/cate/2/7226'\n",
    "html = requests.get(url).content.decode('utf-8')\n",
    "sp = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "for idx,link in enumerate(sp.find_all('h2')):\n",
    "    print('{:4d}. {}'.format(idx+1,link.text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例子：擷取表格資料\n",
    "\n",
    "中央氣象局月平均氣溫表格HTML原始碼:\n",
    "\n",
    "https://www.cwb.gov.tw/V7/climate/monthlyMean/Taiwan_tx.htm\n",
    "\n",
    "\n",
    "      <table width=\"780\" cellpadding=\"2\" cellspacing=\"1\" class=\"Form00\" summary=\"排版用表格\">\n",
    "          <tbody><tr height=\"44\">\n",
    "            <th width=\"150\" height=\"44\" class=\"tab01\">地名</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">一月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">二月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">三月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">四月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">五月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">六月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">七月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">八月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">九月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">十月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">十一月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\" axis=\"month\">十二月</th>\n",
    "            <th width=\"50\" height=\"44\" class=\"tab01\">平均</th>\n",
    "            <th width=\"100\" height=\"44\" class=\"tab01\">統計期間</th>\n",
    "          </tr>\n",
    "          <tr height=\"44\">\n",
    "            <td height=\"44\" class=\"active\" axis=\"item\">淡水</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">15.2</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">15.6</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">17.4</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">21.1</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">24.5</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">26.9</td>\n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">28.8</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">28.6</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">26.7</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">23.7</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">20.6</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">16.9</td>            \n",
    "            <td class=\"whitetd\" width=\"36\" height=\"44\">22.2</td>            \n",
    "            <td class=\"whitetd\" width=\"90\" height=\"25\">1981-2010</td>     \n",
    "           </tr>\n",
    "           ...\n",
    "           </table>\n",
    "           \n",
    "平均氣溫表格放在$\\text{<table>}$$\\text{</table>}$標記內。可是那個網頁有許多$\\text{<table>}$標記，不過其中class為Form00為平均氣溫表格。因此table = sp.find_all('table',{'class':'Form00'})可以鎖定以'class'為key, value為'Form00'的那個$\\text{<table>}$標記。\n",
    "\n",
    "      url = 'https://www.cwb.gov.tw/V7/climate/monthlyMean/Taiwan_tx.htm'\n",
    "      html = requests.get(url).content.decode('utf-8')\n",
    "      sp = BeautifulSoup(html,'html.parser')\n",
    "      table = sp.find('table',{'class':'Form00'})\n",
    "\n",
    "表格裡每一列以$\\text{<tr>}$，$\\text{</tr>}$標記標示。下面指令找出$\\text{<table>}$$\\text{</table>}$標記內每一列。\n",
    "\n",
    "      rows = table.find_all('tr')\n",
    "      \n",
    "第一列，為標題列，每一欄以$\\text{<th>}$，$\\text{</th>}$標記標示。下面指令找出$\\text{<tr>}$，$\\text{</tr>}$標記內每一欄。\n",
    "\n",
    "      title = [c.text for c in rows[0].find_all('th')]\n",
    "\n",
    "其他列每一欄以$\\text{<td>}$，$\\text{</td>}$標記標示。下面指令找出$\\text{<tr>}$，$\\text{</tr>}$標記內每一欄，並存放在各自list。\n",
    "\n",
    "      data  = [list() for _ in range(len(title))]\n",
    "\n",
    "      for r in rows[1:]:\n",
    "          for col,cell_data in zip(data,r.find_all('td')):\n",
    "              try:\n",
    "                  col.append(float(cell_data.text))\n",
    "              except ValueError:\n",
    "                  col.append(cell_data.text)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'https://www.cwb.gov.tw/V7/climate/monthlyMean/Taiwan_tx.htm'\n",
    "html = requests.get(url).content.decode('utf-8')\n",
    "sp = BeautifulSoup(html,'html.parser')\n",
    "table = sp.find('table',{'class':'Form00'})\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "title = [c.text for c in rows[0].find_all('th')]\n",
    "data  = [list() for _ in range(len(title))]\n",
    "    \n",
    "for r in rows[1:]:\n",
    "    for col,cell_data in zip(data,r.find_all('td')):\n",
    "        try:\n",
    "            col.append(float(cell_data.text))\n",
    "        except ValueError:\n",
    "            col.append(cell_data.text)\n",
    "            \n",
    "#放入 numpy.ndarray            \n",
    "\n",
    "data_table= np.core.records.fromarrays(data)\n",
    "data_table.dtype.names = title\n",
    "\n",
    "#資料標題\n",
    "print(data_table.dtype.names)\n",
    "\n",
    "#取得第0列資料\n",
    "print(data_table[0])\n",
    "\n",
    "#取得各觀測站五月均溫\n",
    "print(data_table['五月'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用matplotlib繪出平均氣溫圖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import os \n",
    "\n",
    "font = FontProperties(fname=os.environ['WINDIR']+'\\\\Fonts\\\\kaiu.ttf', size=12)\n",
    " \n",
    "plt.figure(figsize=(8,4))\n",
    "for i in range(5):\n",
    "    r = list(data_table[i])\n",
    "    plt.plot(np.arange(len(data_table.dtype.names)-3),r[1:-2],label=r[0])\n",
    "plt.legend(prop=font)\n",
    "plt.title('平均氣溫',fontproperties=font)\n",
    "plt.xticks(np.arange(len(title)-3),title[1:-2],fontproperties=font)\n",
    "plt.ylabel('攝氏',fontproperties=font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例子：擷取所有連結    \n",
    "HTML連結格式為:\n",
    "\n",
    "     <a href='https://tw.yahoo.com/?p=us'>本文</a>\n",
    "\n",
    "所以\n",
    "\n",
    "      all_links = sp.find_all('a')\n",
    "     \n",
    "得到所有$\\text{<a ....>....</a>}$段落。假設link為以上連結為例子，\n",
    "\n",
    "+ link.get('href')得到'https://tw.yahoo.com/?p=us'\n",
    "+ link.text得到'本文'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = 'https://udn.com/news/index'\n",
    "html = requests.get(url).content.decode('utf-8')\n",
    "sp = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "for idx,link in enumerate(sp.find_all('a')):\n",
    "    href = link.get('href')\n",
    "    if href is not None and href.startswith('http'):\n",
    "        print('{:4d} text:{:<s}, link:{:>s}'.format(idx+1,link.text,href))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例子：擷取所有圖形檔  \n",
    "下面例子需要用到pillow模組\n",
    "\n",
    "    conda install -c anaconda pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import io\n",
    "import re\n",
    "\n",
    "url = 'https://udn.com/news/story/7934/3526132'\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Safari/537.36',\n",
    "           'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Connection' : 'Keep-Alive',\n",
    "        'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        'Accept-Encoding':'gzip, deflate, sdch',\n",
    "        'Accept-Languate': 'en-US,en;q=0.8'}\n",
    "\n",
    "uc  = urlparse(url)\n",
    "print(uc.scheme,uc.hostname)\n",
    "domain = '{}://{}'.format(uc.scheme,uc.hostname)\n",
    "print(domain)\n",
    "\n",
    "html = requests.get(url,headers=headers).content.decode('utf-8')\n",
    "\n",
    "sp = BeautifulSoup(html,'html.parser')\n",
    "for idx,link in enumerate(sp.find_all(['a','img'])):\n",
    "    href = link.get('href')\n",
    "    src  = link.get('src')\n",
    "    for t in [href, src]:\n",
    "        if t is not None and ('.jpg' in t or '.png' in t):\n",
    "            if t.startswith('http'):\n",
    "                img_path = t  \n",
    "            elif t.startswith('//'):\n",
    "                img_path = 'https:'+t\n",
    "            else:\n",
    "                domain+t\n",
    "            print(img_path)\n",
    "            print('filename:{}'.format(re.search('[^/]+((.jpg)|(.png))',img_path).group()))\n",
    "            image = urlopen(img_path)\n",
    "            img = Image.open(image)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=color:blue>透過Selenium擷取網頁資料</span>\n",
    "安裝\n",
    "\n",
    "     conda install -c conda-forge selenium\n",
    "\n",
    "安裝各瀏覽器的webdriver載點https://www.seleniumhq.org/about/platforms.jsp  \n",
    "+ 如Chrome web driver:https://sites.google.com/a/chromium.org/chromedriver/home   \n",
    "\n",
    "並將webdriver(如chromedriver.exe)放在Python執行的目錄內。測試下面範例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 操作瀏覽器函式\n",
    "\n",
    "webdriver方法       |說明\n",
    "----------------------|-------------\n",
    "refresh() |<p align='left'> 重新整理頁面</p>\n",
    "back() |<p align='left'> 回上一頁</p>\n",
    "forward() |<p align='left'> 到下一頁</p>\n",
    "close() |<p align='left'> 關視窗</p>\n",
    "quit() |<p align='left'> 結束瀏覽器</p>\n",
    "get(url)|<p align='left'> 瀏覽url這網址</p>\n",
    "current_url|<p align='left'> 目前網址</p>\n",
    "title|<p align='left'> 網頁標題</p>\n",
    "page_source|<p align='left'> 網頁原始碼</p>\n",
    "save_screenshot(pngfile) |<p align='left'> 存目前網頁畫面於png檔</p>\n",
    "get_window_position() |<p align='left'> 取得視窗左上角位置</p>\n",
    "set_window_position(x,y) |<p align='left'> 設定視窗左上角位置</p>\n",
    "maximize_window() |<p align='left'> 最大化視窗</p>\n",
    "get_window_size() |<p align='left'> 取得視窗大小</p>\n",
    "set_window_size(x,y) |<p align='left'> 設定視窗大小</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "urls = ['https://www.cwb.gov.tw/V7/','https://tw.yahoo.com/?p=us']\n",
    "web = webdriver.Chrome()\n",
    "for idx,url in enumerate(urls):\n",
    "    web.get(url)\n",
    "    web.save_screenshot('screenshot_{}.png'.format(idx))\n",
    "web.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "fig = plt.figure(figsize=(15,30))\n",
    "for idx in range(len(urls)):\n",
    "    img = mpimg.imread('screenshot_{}.png'.format(idx))\n",
    "    plt.subplot(1,2,idx+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 網頁元素檢索功能\n",
    "\n",
    "基本步驟範例\n",
    "\n",
    "    web = webdriver.Chrome()\n",
    "    web.get(url)\n",
    "    \n",
    "    # 檢索網頁元素，通常元素id為唯一，比較好找\n",
    "    element = web.find_element_by_id(id) \n",
    "    \n",
    "    # 操作網頁元素\n",
    "    element.send_keys(value) \n",
    "    element.submit() # 提交\n",
    "\n",
    "webdriver元素檢索方法       |說明\n",
    "----------------------|-------------\n",
    "<b>find_element_by_X(value)</b> |<p align='left'> 使用X檢索，取得第一個符合的元素</p>\n",
    "-----------------------------------------------|-------------------------------------------------\n",
    "find_element_by_class_name(name)|<p align='left'> 使用類別名稱檢索</p>\n",
    "find_element_by_css_selector(selector)|<p align='left'> 使用CSS選擇器檢索</p>\n",
    "find_element_by_id(id)|<p align='left'> 使用id檢索</p>\n",
    "find_element_by_link_text(text)|<p align='left'> 使用連結文字檢索</p>\n",
    "find_element_by_name(name)|<p align='left'> 使用名稱檢索</p>\n",
    "find_element_by_tag_name(name)|<p align='left'> 使用HTML標籤檢索</p>\n",
    "-----------------------------------------------|-------------------------------------------------\n",
    "<b>find_elements_by_X</b> | <p align='left'> 使用X檢索，取得所有符合的元素</p>\n",
    "\n",
    "\n",
    "\n",
    "webdriver元素操作方法       |說明\n",
    "----------------------|-------------\n",
    "clear() | <p align='left'> 清除內容</p>\n",
    "click() | <p align='left'> 點擊，通常用於按鈕、連結、選單</p>\n",
    "send_keys(value) | <p align='left'> 對此元素送出字串</p>\n",
    "submit() |<p align='left'> 提交</p>\n",
    "is_displayed() | <p align='left'> 此元素是否可見</p>\n",
    "is_enabled() | <p align='left'> 此元素是否可用</p>\n",
    "is_selected() | <p align='left'> 此元素是否被選定</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "web = webdriver.Chrome()\n",
    "web.maximize_window()\n",
    "web.get(\"https://www.google.com\")\n",
    "\n",
    "#找到輸入框\n",
    "element = web.find_element_by_name(\"q\")\n",
    "\n",
    "#輸入\n",
    "element.send_keys(\"中央氣象局\")\n",
    "\n",
    "#提交\n",
    "element.submit()\n",
    "\n",
    "#web.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "web = webdriver.Chrome()\n",
    "web.maximize_window()\n",
    "web.get(\"https://www.youtube.com\")\n",
    "\n",
    "#找到輸入框\n",
    "element = web.find_element_by_id(\"search\")\n",
    "\n",
    "#輸入\n",
    "element.send_keys(\"selenium Python\")\n",
    "\n",
    "#按搜尋\n",
    "search_btn = web.find_element_by_id(\"search-icon-legacy\")\n",
    "search_btn.click()\n",
    "# Get scroll height\n",
    "last_height = -1\n",
    "for idx in range(500):\n",
    "    # Scroll down to bottom\n",
    "    web.execute_script(\"window.scrollTo(0, window.scrollY + 800);\")\n",
    "    # Wait to load page\n",
    "    time.sleep(.5)\n",
    "    current_height = web.execute_script(\"return window.scrollY\")\n",
    "    if last_height == current_height:\n",
    "        print('stop')\n",
    "        break\n",
    "    last_height = current_height\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(web.page_source.splitlines()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
